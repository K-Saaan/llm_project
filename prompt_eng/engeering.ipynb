{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ ì–¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.schema import HumanMessage, SystemMessage, Document\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API_KEY ì„ ì–¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ì—…ì„ ìˆ˜í–‰í•  chat ì„ ì–¸\n",
    "chat = OpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_template = \"\"\"\n",
    "{intro}\n",
    "{input_prompt}\n",
    " \"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_template = \"\"\"\n",
    "ë„ˆëŠ” cs ë‹´ë‹¹ìì•¼ \\n\n",
    "ì£¼ì–´ì§„ textë¥¼ ë¶„ì„í•´ì„œ ê¸ì • ë¦¬ë·°ì¸ì§€ ë¶€ì • ë¦¬ë·°ì¸ì§€ í™•ì¸í•˜ë ¤ê³  í•´ \\n\n",
    "ì£¼ì–´ì§€ëŠ” ë¦¬ë·°ê°€ ê¸ì •ì´ë©´ 'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤', ë¶€ì •ì´ë©´ 'ë¶€ì • ë¦¬ë·°ì••ë‹ˆë‹¤' ë¡œ ë¶„ë¥˜í•´ì¤˜\n",
    "\"\"\"\n",
    "intro_prompt = PromptTemplate.from_template(intro_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template = \"\"\" \n",
    "<text> {input} </text>\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(input_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    (\"intro\", intro_prompt),\n",
    "    (\"input_prompt\", input_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt í˜•ì‹ì„ dataframeìœ¼ë¡œ ë¶ˆëŸ¬ì˜´\n",
    "with open('../data/ì‡¼í•‘/naver_shopping.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data_split = [x.strip().split('\\t') for x in data[0:]]\n",
    "df = pd.DataFrame(data_split, columns=['score', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nê°œ ë§Œí¼ ì¶”ì¶œí•˜ì—¬ inputìœ¼ë¡œ ì €ì¥\n",
    "df_sampled = df.sample(n=50, random_state=42)\n",
    "\n",
    "formatted_prompts = [pipeline_prompt.format(\n",
    "    input=row['review']) for index, row in df_sampled.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µì„ ì €ì¥í•  response ì„ ì–¸\n",
    "responses = []\n",
    "# formatted_promptsì˜ inputì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜¤ê¸° ìˆ˜í–‰\n",
    "for prompt in formatted_prompts:\n",
    "    response = chat(prompt)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ê²°ê³¼ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥\n",
    "df_sampled['tag'] = df_sampled['score'].apply(lambda x: 'ê¸ì •' if int(x) >=3 else 'ë¶€ì •')\n",
    "df_sampled['predict'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_negative(text):\n",
    "    if 'ë¶€ì •' in text:\n",
    "        return 'ë¶€ì •'\n",
    "    elif 'ê¸ì •' in text:\n",
    "        return 'ê¸ì •'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„: 84.00%\n"
     ]
    }
   ],
   "source": [
    "# 'ê¸ë¶€ì •'ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df_sampled['predict'] = df_sampled['predict'].apply(extract_negative)\n",
    "\n",
    "df_sampled['is_correct'] = df_sampled['predict'] == df_sampled['tag']\n",
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = df_sampled['is_correct'].mean()\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot \n",
    "## N=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full_template \n",
    "- ì „ì²´ í…œí”Œë¦¿ì˜ í˜•ì‹ ì •ì˜\n",
    "\n",
    "    - intro : ì´ˆì…ì— í•´ë‹¹í•˜ë©°, ì•ìœ¼ë¡œ ì–´ë–¤ ë‚´ìš©ì´ ì˜¤ê³  ì–´ë–¤ ê²°ê³¼ê°’ì„ ì›í•˜ëŠ”ì§€ ì •ì˜\n",
    "    - example : ì˜ˆì‹œ ë°ì´í„° ì •ì˜\n",
    "    - input_prompt : ì•ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê²°ê³¼ê°’ì„ ë°›ê¸° ìœ„í•œ input ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_template = \"\"\"\n",
    "{intro}\n",
    "{example}\n",
    "{input_prompt}\n",
    " \"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intro_template ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_template = \"\"\"\n",
    "ë„ˆëŠ” cs ë‹´ë‹¹ìì•¼ \\n\n",
    "ì£¼ì–´ì§„ textë¥¼ ë¶„ì„í•´ì„œ ê¸ì • ë¦¬ë·°ì¸ì§€ ë¶€ì • ë¦¬ë·°ì¸ì§€ í™•ì¸í•˜ë ¤ê³  í•´ \\n\n",
    "ì˜ˆì‹œ ë°ì´í„°ëŠ” <text> ë¦¬ë·° </text> <tag> ê¸ì •/ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤ </tag> í˜•ì‹ì˜ xmlë¡œ ì£¼ì–´ì§ˆê±°ì•¼ \\n\n",
    "ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë³´ê³  ì£¼ì–´ì§€ëŠ” ë¦¬ë·°ê°€ ê¸ì •ì´ë©´ 'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤', ë¶€ì •ì´ë©´ 'ë¶€ì • ë¦¬ë·°ì••ë‹ˆë‹¤' ë¡œ ë¶„ë¥˜í•´ì¤˜\n",
    "\"\"\"\n",
    "intro_prompt = PromptTemplate.from_template(intro_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example_template ì •ì˜\n",
    "- text : ë¦¬ë·° í…ìŠ¤íŠ¸\n",
    "- tag : textì— ëŒ€í•œ ê¸/ë¶€ì • ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\" \n",
    "<text>'ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ì—‰ì„±í•˜ê¸´ í•˜ì§€ë§Œ í¸í•˜ê³  ê°€ì„±ë¹„ ìµœê³ ì˜ˆìš”.'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „í™”í–ˆë”ë‹ˆ ë°”ë¡œì£¼ì‹ ë‹¤í–ˆì§€ë§Œ ë°°ì†¡ë„ ëˆ„ë½ë˜ì–´ìˆì—ˆë„¤ìš”.. í™•ì¸ì•ˆí•˜ê³  ë°”ë¡œ ì„ ë¬¼í–ˆìœ¼ë©´ í°ì¼ë‚ ë»”í–ˆë„¤ìš”..ì´ë ‡ê²Œ ë°°ì†¡ì´ ì˜¤ë˜ê±¸ë ¸ìœ¼ë©´ ì‚¬ëŠ”ê±° ë‹¤ì‹œ ìƒê°í–ˆì„ê±°ê°™ì•„ìš” ì•„ì‰½ë„¤ìš”..'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì²˜ìŒ ì“¸ë•Œë§Œ ì¢‹ê³  ì“°ë‹¤ë³´ë‹ˆ ì˜ìëº„ë•Œ ì†Œë¦¬ ê³„ì† ë‚˜ìš” ê·¸ë˜ì„œ ë¶™ì´ëŠ”ë¶€ì§í¬ ë§ë¶™ì˜€ëŠ”ë° ì—¬ì „íˆ ëŒë¦¬ë„¤ìš” ë¹„ì¶”ì—ìš” í…Œë‹ˆìŠ¤ê³µìœ¼ë¡œ ì‚´ê»„ ì´ìœê±° ì‚°ë‹¤ê³  ì´ê±° ì‚¬ì„œ í›„íšŒë˜ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_template ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template = \"\"\" \n",
    "<text> {input} </text>\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(input_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    (\"intro\", intro_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"input_prompt\", input_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt pipeline ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µì„ ì €ì¥í•  response ì„ ì–¸\n",
    "responses = []\n",
    "# formatted_promptsì˜ inputì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜¤ê¸° ìˆ˜í–‰\n",
    "for prompt in formatted_prompts:\n",
    "    response = chat(prompt)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ê²°ê³¼ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥\n",
    "df_sampled['tag'] = df_sampled['score'].apply(lambda x: 'ê¸ì •' if int(x) >=3 else 'ë¶€ì •')\n",
    "df_sampled['predict'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„: 86.00%\n"
     ]
    }
   ],
   "source": [
    "# 'ê¸ë¶€ì •'ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df_sampled['predict'] = df_sampled['predict'].apply(extract_negative)\n",
    "\n",
    "df_sampled['is_correct'] = df_sampled['predict'] == df_sampled['tag']\n",
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = df_sampled['is_correct'].mean()\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot \n",
    "## N=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\" \n",
    "<text>'ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ì—‰ì„±í•˜ê¸´ í•˜ì§€ë§Œ í¸í•˜ê³  ê°€ì„±ë¹„ ìµœê³ ì˜ˆìš”.'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „í™”í–ˆë”ë‹ˆ ë°”ë¡œì£¼ì‹ ë‹¤í–ˆì§€ë§Œ ë°°ì†¡ë„ ëˆ„ë½ë˜ì–´ìˆì—ˆë„¤ìš”.. í™•ì¸ì•ˆí•˜ê³  ë°”ë¡œ ì„ ë¬¼í–ˆìœ¼ë©´ í°ì¼ë‚ ë»”í–ˆë„¤ìš”..ì´ë ‡ê²Œ ë°°ì†¡ì´ ì˜¤ë˜ê±¸ë ¸ìœ¼ë©´ ì‚¬ëŠ”ê±° ë‹¤ì‹œ ìƒê°í–ˆì„ê±°ê°™ì•„ìš” ì•„ì‰½ë„¤ìš”..'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì²˜ìŒ ì“¸ë•Œë§Œ ì¢‹ê³  ì“°ë‹¤ë³´ë‹ˆ ì˜ìëº„ë•Œ ì†Œë¦¬ ê³„ì† ë‚˜ìš” ê·¸ë˜ì„œ ë¶™ì´ëŠ”ë¶€ì§í¬ ë§ë¶™ì˜€ëŠ”ë° ì—¬ì „íˆ ëŒë¦¬ë„¤ìš” ë¹„ì¶”ì—ìš” í…Œë‹ˆìŠ¤ê³µìœ¼ë¡œ ì‚´ê»„ ì´ìœê±° ì‚°ë‹¤ê³  ì´ê±° ì‚¬ì„œ í›„íšŒë˜ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ê°€ì„±ë¹„ ê´œì°®ìŠµë‹ˆë‹¤ ë°”í€´ê°€ ê³ ì •ëœë‹¤ë©´ ë³„ë‹¤ì„¯ê°œì§œë¦°ë°...'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ì¤€ì‚¬ëŒë„ ë°›ì€ì‚¬ëŒë„ ëª¨ë‘ ë§Œì¡±í–ˆì–´ìš”^^'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_template = \"\"\" \n",
    "<text> {input} </text>\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(input_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    (\"intro\", intro_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"input_prompt\", input_prompt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µì„ ì €ì¥í•  response ì„ ì–¸\n",
    "responses = []\n",
    "# formatted_promptsì˜ inputì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜¤ê¸° ìˆ˜í–‰\n",
    "for prompt in formatted_prompts:\n",
    "    response = chat(prompt)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ê²°ê³¼ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥\n",
    "df_sampled['tag'] = df_sampled['score'].apply(lambda x: 'ê¸ì •' if int(x) >=3 else 'ë¶€ì •')\n",
    "df_sampled['predict'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„: 78.00%\n"
     ]
    }
   ],
   "source": [
    "# 'ê¸ë¶€ì •'ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df_sampled['predict'] = df_sampled['predict'].apply(extract_negative)\n",
    "\n",
    "df_sampled['is_correct'] = df_sampled['predict'] == df_sampled['tag']\n",
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = df_sampled['is_correct'].mean()\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot \n",
    "## N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\" \n",
    "<text>'ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ì—‰ì„±í•˜ê¸´ í•˜ì§€ë§Œ í¸í•˜ê³  ê°€ì„±ë¹„ ìµœê³ ì˜ˆìš”.'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „í™”í–ˆë”ë‹ˆ ë°”ë¡œì£¼ì‹ ë‹¤í–ˆì§€ë§Œ ë°°ì†¡ë„ ëˆ„ë½ë˜ì–´ìˆì—ˆë„¤ìš”.. í™•ì¸ì•ˆí•˜ê³  ë°”ë¡œ ì„ ë¬¼í–ˆìœ¼ë©´ í°ì¼ë‚ ë»”í–ˆë„¤ìš”..ì´ë ‡ê²Œ ë°°ì†¡ì´ ì˜¤ë˜ê±¸ë ¸ìœ¼ë©´ ì‚¬ëŠ”ê±° ë‹¤ì‹œ ìƒê°í–ˆì„ê±°ê°™ì•„ìš” ì•„ì‰½ë„¤ìš”..'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì²˜ìŒ ì“¸ë•Œë§Œ ì¢‹ê³  ì“°ë‹¤ë³´ë‹ˆ ì˜ìëº„ë•Œ ì†Œë¦¬ ê³„ì† ë‚˜ìš” ê·¸ë˜ì„œ ë¶™ì´ëŠ”ë¶€ì§í¬ ë§ë¶™ì˜€ëŠ”ë° ì—¬ì „íˆ ëŒë¦¬ë„¤ìš” ë¹„ì¶”ì—ìš” í…Œë‹ˆìŠ¤ê³µìœ¼ë¡œ ì‚´ê»„ ì´ìœê±° ì‚°ë‹¤ê³  ì´ê±° ì‚¬ì„œ í›„íšŒë˜ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ê°€ì„±ë¹„ ê´œì°®ìŠµë‹ˆë‹¤ ë°”í€´ê°€ ê³ ì •ëœë‹¤ë©´ ë³„ë‹¤ì„¯ê°œì§œë¦°ë°...'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ì¤€ì‚¬ëŒë„ ë°›ì€ì‚¬ëŒë„ ëª¨ë‘ ë§Œì¡±í–ˆì–´ìš”^^'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì‘ì•„ì„œìš” ë‚˜ì¤‘ì— ë¨¼ì§€ë¨¹ëŠ”ì‹ë¬¼ì´ë‚˜ ë„£ì–´ì•¼ê² ì–´ìš” ë¬¼ê±´ì€ í ì—†ìŠµë‹ˆë‹¤'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì¬êµ¬ë§¤ 3í†µì§¼ëŒ€ ì•„ì£¼ì¢‹ë„¤ìš”!ê°•ì¶”'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì‹¤ë§ì´ë„¤ìš” ë§ˆë¬´ë¦¬ì²˜ë¦¬ê°€ ë„ˆë¬´ì—‰ì„±í•©ë‹ˆë‹¤'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ë°°ì†¡ëŠë¦¼.. ë ˆê¹…ìŠ¤ ë°‘ë‹¨ ë§ˆë¬´ë¦¬ ì—‰ì„±í•¨.. ìˆ˜íŠ¸í™”ë©´ë³´ë‹¤ ë°ìŒ..ì£¼í™©ìƒ‰ê°™ì•„ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì‘ì€ ì‚¬ì´ì¦ˆì´ì§€ë§Œ ì‹œì›í•˜ê³  ì¢‹ì•„ìš”. ì„¤ì¹˜ ì—„ì²­ ë¹¨ë¦¬ ì¡ì•„ì£¼ì…¨ì–´ìš”. ì„¤ì¹˜ë¹„ê°€ ë¬¼ê±´ê°’ì˜ ê±°ì˜ 2ë°°ì¸ê²Œ ì¢€ ì†ìƒí•˜ì§€ë§Œ ë„˜ ê¹”ë”íˆ ì‘ì—… í•´ ì£¼ì‹œê³  ì¹œì ˆíˆ ëŒ€í•´ì£¼ì…¨ì–´ìš”. ì¶”ì²œ!'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "input_template = \"\"\" \n",
    "<text> {input} </text>\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(input_template)\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"input_prompt\", input_prompt),\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µì„ ì €ì¥í•  response ì„ ì–¸\n",
    "responses = []\n",
    "# formatted_promptsì˜ inputì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜¤ê¸° ìˆ˜í–‰\n",
    "for prompt in formatted_prompts:\n",
    "    response = chat(prompt)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ê²°ê³¼ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥\n",
    "df_sampled['tag'] = df_sampled['score'].apply(lambda x: 'ê¸ì •' if int(x) >=3 else 'ë¶€ì •')\n",
    "df_sampled['predict'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„: 86.00%\n"
     ]
    }
   ],
   "source": [
    "# 'ê¸ë¶€ì •'ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df_sampled['predict'] = df_sampled['predict'].apply(extract_negative)\n",
    "\n",
    "df_sampled['is_correct'] = df_sampled['predict'] == df_sampled['tag']\n",
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = df_sampled['is_correct'].mean()\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot\n",
    "## N=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\" \n",
    "<text>'ì•„ì£¼ì¢‹ì•„ìš” ë°”ì§€ ì •ë§ ì¢‹ì•„ì„œ2ê°œ ë” êµ¬ë§¤í–ˆì–´ìš” ì´ê°€ê²©ì— ëŒ€ë°•ì…ë‹ˆë‹¤. ë°”ëŠì§ˆì´ ì¡°ê¸ˆ ì—‰ì„±í•˜ê¸´ í•˜ì§€ë§Œ í¸í•˜ê³  ê°€ì„±ë¹„ ìµœê³ ì˜ˆìš”.'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ìš©ìœ¼ë¡œ ë¹¨ë¦¬ ë°›ì•„ì„œ ì „ë‹¬í–ˆì–´ì•¼ í•˜ëŠ” ìƒí’ˆì´ì—ˆëŠ”ë° ë¨¸ê·¸ì»µë§Œ ì™€ì„œ ë‹¹í™©í–ˆìŠµë‹ˆë‹¤. ì „í™”í–ˆë”ë‹ˆ ë°”ë¡œì£¼ì‹ ë‹¤í–ˆì§€ë§Œ ë°°ì†¡ë„ ëˆ„ë½ë˜ì–´ìˆì—ˆë„¤ìš”.. í™•ì¸ì•ˆí•˜ê³  ë°”ë¡œ ì„ ë¬¼í–ˆìœ¼ë©´ í°ì¼ë‚ ë»”í–ˆë„¤ìš”..ì´ë ‡ê²Œ ë°°ì†¡ì´ ì˜¤ë˜ê±¸ë ¸ìœ¼ë©´ ì‚¬ëŠ”ê±° ë‹¤ì‹œ ìƒê°í–ˆì„ê±°ê°™ì•„ìš” ì•„ì‰½ë„¤ìš”..'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì²˜ìŒ ì“¸ë•Œë§Œ ì¢‹ê³  ì“°ë‹¤ë³´ë‹ˆ ì˜ìëº„ë•Œ ì†Œë¦¬ ê³„ì† ë‚˜ìš” ê·¸ë˜ì„œ ë¶™ì´ëŠ”ë¶€ì§í¬ ë§ë¶™ì˜€ëŠ”ë° ì—¬ì „íˆ ëŒë¦¬ë„¤ìš” ë¹„ì¶”ì—ìš” í…Œë‹ˆìŠ¤ê³µìœ¼ë¡œ ì‚´ê»„ ì´ìœê±° ì‚°ë‹¤ê³  ì´ê±° ì‚¬ì„œ í›„íšŒë˜ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ê°€ì„±ë¹„ ê´œì°®ìŠµë‹ˆë‹¤ ë°”í€´ê°€ ê³ ì •ëœë‹¤ë©´ ë³„ë‹¤ì„¯ê°œì§œë¦°ë°...'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì„ ë¬¼ì¤€ì‚¬ëŒë„ ë°›ì€ì‚¬ëŒë„ ëª¨ë‘ ë§Œì¡±í–ˆì–´ìš”^^'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì‘ì•„ì„œìš” ë‚˜ì¤‘ì— ë¨¼ì§€ë¨¹ëŠ”ì‹ë¬¼ì´ë‚˜ ë„£ì–´ì•¼ê² ì–´ìš” ë¬¼ê±´ì€ í ì—†ìŠµë‹ˆë‹¤'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì¬êµ¬ë§¤ 3í†µì§¼ëŒ€ ì•„ì£¼ì¢‹ë„¤ìš”!ê°•ì¶”'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì‹¤ë§ì´ë„¤ìš” ë§ˆë¬´ë¦¬ì²˜ë¦¬ê°€ ë„ˆë¬´ì—‰ì„±í•©ë‹ˆë‹¤'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ë°°ì†¡ëŠë¦¼.. ë ˆê¹…ìŠ¤ ë°‘ë‹¨ ë§ˆë¬´ë¦¬ ì—‰ì„±í•¨.. ìˆ˜íŠ¸í™”ë©´ë³´ë‹¤ ë°ìŒ..ì£¼í™©ìƒ‰ê°™ì•„ìš”'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì‘ì€ ì‚¬ì´ì¦ˆì´ì§€ë§Œ ì‹œì›í•˜ê³  ì¢‹ì•„ìš”. ì„¤ì¹˜ ì—„ì²­ ë¹¨ë¦¬ ì¡ì•„ì£¼ì…¨ì–´ìš”. ì„¤ì¹˜ë¹„ê°€ ë¬¼ê±´ê°’ì˜ ê±°ì˜ 2ë°°ì¸ê²Œ ì¢€ ì†ìƒí•˜ì§€ë§Œ ë„˜ ê¹”ë”íˆ ì‘ì—… í•´ ì£¼ì‹œê³  ì¹œì ˆíˆ ëŒ€í•´ì£¼ì…¨ì–´ìš”. ì¶”ì²œ!'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ë³€í•˜ì§€ì•ŠëŠ” ê¾€ëŒì´ğŸ‘'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì¬êµ¬ë§¤ ì¢‹ì•„ìš”.ì•„ì´ê°€ ì•„ì£¼ ì¢‹ì•„í•´ìš”â™¡'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ë§¤ìš° ì‹ ì„  ì—´ì–´ë†“ìœ¼ë‹ˆê¹Œ ì ì  í™œë°œí•´ì§. í™©ì¥ì´ ê°€ë“ ìˆ˜ìœ¨ë„ 80í¼ ì´ìƒ, ì‹ ì„ í•´ì„œ ì‚´ê²°ì´ ê·¸ëŒ€ë¡œ ëŠê»´ì§ ë°”ë¡œ ë˜ ë¨¹ê³  ì‹¶ìŒ'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'í˜„ê´€ë¬¸ì˜†ì— í™ˆë°”ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ë° ì´ë»ìš” í•œê°€ì§€ ë‹¨ì ì€ ì•„ë˜ ìˆ˜ë‚©í• ë•Œ ê¸°ë‘¥ë•Œë¬¸ì— ë°•ìŠ¤ê°™ì€ê²Œ ëª»ë“¤ì–´ê°€ìš”.. ã…œ'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ê³µí•­ì—ì„œ ì˜ ìˆ˜ë ¹í•˜ì—¬ ì˜ì“°ê³  ìˆìŠµë‹ˆë‹¤'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ë½ë½ì´ ê¸°ì‚¬ë‹˜ì´ ì—‰ëš±í•œë° ë‘ê³  ê°”ì§€ë§Œ í•˜ë£¨ë§Œì— ë‹¤ì‹œ ì™€ì„œ ê°ì‚¬'</text>\n",
    "<tag>'ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ê°€ê²©ëŒ€ë¹„ ì¢€ ë¶€ì¡±í•œê²Œ ë§ì€ë“¯'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì•ˆì¢‹ì•„ìš” ì‹ ìƒì•„ì¸ë° ì˜ì•ˆë¨¹ìœ¼ë ¤ê³  í•˜ë„¤ìš”ã…œë„ˆë¬´ ì¡°ê¸ˆì”©ë‚˜ì™€ì„œ ë¹¨ê¸°í˜ë“ ê°€ë´ìš” ê·¸ë¦°ë§˜ì“°ë‹¤ê°€ ë°”ê¿”ë´¤ëŠ”ë° ì‹¤íŒ¨ã…œ'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì¬êµ¬ë§¤ ì´ ê³°íŒ¡ì´ëƒ„ìƒˆ ë‚˜ëŠ” ìƒìì— ë‹´ì•„ì£¼ëŠ” ì™œ ê·¸ëŸ°ê±´ê°€ìš”? ì¢…ì´ì§€ê´€ì„ ë‹´ì•„ì£¼ëŠ”ë° ê³°íŒ¡ì´ í•€ ìƒìì— ë‹´ì•„ì£¼ë©´ ì°ì°í•´ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•©ë‹ˆê¹Œ? ë„ˆë¬´í•˜ëŠ”ê±° ì•„ë‹™ë‹ˆê¹Œ?'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "<text>'ì‚¬ì´ì¦ˆê°€ ì¢€ í°í¸ì´ê³  ì±™ë¶€ë¶„ ë§ˆê°ì²˜ë¦¬ì™€ ëª¨ìì˜†ë©´ ë§ˆê°ì²˜ë¦¬ê°€ ì¢€ ì—‰ì„±í•˜ë„¤ìš” ê°€ê²©ëŒ€ë¹„ ê·¸ì € ê·¸ë ‡ìŠµë‹ˆë‹¤...'</text>\n",
    "<tag>'ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤'</tag>\n",
    "\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "input_template = \"\"\" \n",
    "<text> {input} </text>\n",
    "\"\"\"\n",
    "input_prompt = PromptTemplate.from_template(input_template)\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"input_prompt\", input_prompt),\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=prompts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µì„ ì €ì¥í•  response ì„ ì–¸\n",
    "responses = []\n",
    "# formatted_promptsì˜ inputì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜¤ê¸° ìˆ˜í–‰\n",
    "for prompt in formatted_prompts:\n",
    "    response = chat(prompt)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ë‹µ ê²°ê³¼ê°’ê³¼ ì‹¤ì œ ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥\n",
    "df_sampled['tag'] = df_sampled['score'].apply(lambda x: 'ê¸ì •' if int(x) >=3 else 'ë¶€ì •')\n",
    "df_sampled['predict'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •í™•ë„: 84.00%\n"
     ]
    }
   ],
   "source": [
    "# 'ê¸ë¶€ì •'ë§Œ ì¶”ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df_sampled['predict'] = df_sampled['predict'].apply(extract_negative)\n",
    "\n",
    "df_sampled['is_correct'] = df_sampled['predict'] == df_sampled['tag']\n",
    "# ì •í™•ë„ ê³„ì‚°\n",
    "accuracy = df_sampled['is_correct'].mean()\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
